<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.8.4" />
<title>aioextensions API documentation</title>
<meta name="description" content="High performance functions to work with the async IO …" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js" integrity="sha256-eOgo0OtLL4cdq7RdwRUiGKLX9XsIJ7nGhWEKbohmVAQ=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Package <code>aioextensions</code></h1>
</header>
<section id="section-intro">
<p>High performance functions to work with the async IO.</p>
<p><a href="https://pypi.org/project/aioextensions"><img alt="Release" src="https://img.shields.io/pypi/v/aioextensions?color=success&amp;label=Release&amp;style=flat-square"></a>
<a href="https://kamadorueda.github.io/aioextensions/"><img alt="Documentation" src="https://img.shields.io/badge/Documentation-click_here!-success?style=flat-square"></a>
<a href="https://pypi.org/project/aioextensions"><img alt="Downloads" src="https://img.shields.io/pypi/dm/aioextensions?label=Downloads&amp;style=flat-square"></a>
<a href="https://pypi.org/project/aioextensions"><img alt="Status" src="https://img.shields.io/pypi/status/aioextensions?label=Status&amp;style=flat-square"></a>
<a href="https://kamadorueda.github.io/aioextensions/"><img alt="Coverage" src="https://img.shields.io/badge/Coverage-100%25-success?style=flat-square"></a>
<a href="https://github.com/kamadorueda/aioextensions/blob/latest/LICENSE.md"><img alt="License" src="https://img.shields.io/pypi/l/aioextensions?color=success&amp;label=License&amp;style=flat-square"></a></p>
<h1 id="rationale">Rationale</h1>
<p>Modern services deal with a bunch of different tasks to perform:</p>
<p><img alt="Latency comparison" src="https://raw.githubusercontent.com/kamadorueda/aioextensions/latest/docs/static/latency.png"></p>
<p>The important thing to note is that tasks can be categorized in two groups:</p>
<h2 id="cpu-bound-tasks">CPU bound tasks</h2>
<p>Those that happen inside the CPU, with very low latency and exploit the full
potential of the hardware in the computer.</p>
<p><img alt="Resources of an CPU bound task" src="https://raw.githubusercontent.com/kamadorueda/aioextensions/latest/docs/static/resources_cpu_task.png"></p>
<p>Examples of these tasks include:</p>
<table>
<thead>
<tr>
<th>Task</th>
<th align="right">Latency in seconds</th>
</tr>
</thead>
<tbody>
<tr>
<td>CPU computation</td>
<td align="right">0.000000001</td>
</tr>
<tr>
<td>Memory access</td>
<td align="right">0.0000001</td>
</tr>
<tr>
<td>CPU Processing (1KB)</td>
<td align="right">0.000003</td>
</tr>
<tr>
<td>Memory read (1MB)</td>
<td align="right">0.00025</td>
</tr>
</tbody>
</table>
<h2 id="io-bound-tasks">IO bound tasks</h2>
<p>Those that happen over a wire that transports data, with very high latencies
and do not exploit the full potential of the hardware because the only thing to
do is waiting until the data gets to the other end and comes back (round-trip)</p>
<p><img alt="Resources of an IO bound task" src="https://raw.githubusercontent.com/kamadorueda/aioextensions/latest/docs/static/resources_io_task.png"></p>
<p>Examples of these tasks include:</p>
<table>
<thead>
<tr>
<th>Task</th>
<th align="right">Latency in seconds</th>
</tr>
</thead>
<tbody>
<tr>
<td>Disk access</td>
<td align="right">0.00015</td>
</tr>
<tr>
<td>HTTP to localhost</td>
<td align="right">0.0005</td>
</tr>
<tr>
<td>Disk read (1MB)</td>
<td align="right">0.02</td>
</tr>
<tr>
<td>HTTP to internet</td>
<td align="right">0.15</td>
</tr>
</tbody>
</table>
<h2 id="standard-library">Standard library</h2>
<p>The Python's standard library offers the <a href="https://docs.python.org/3/library/concurrent.futures.html">concurrent.futures</a> module to work with
these problems.</p>
<p>You can use it to create a pool of Threads or Processes and send work to them:</p>
<ul>
<li>Work done by a pool of Processes is executed in parallel: all CPU cores are
being used.</li>
<li>Work done by a pool of Threads is done concurrently: tasks execution is
overlapping, but not necessarily parallel: only 1 task can use the CPU
while the remaining ones are waiting the
<a href="https://realpython.com/python-gil">GIL</a>.</li>
</ul>
<p>This is fine for most use cases, however, sometimes you need to solve
a mixture of tasks types in a hardware efficient way.</p>
<h3 id="solving-cpu-bound-tasks">Solving CPU bound tasks</h3>
<p>The optimal way to perform CPU bound tasks is to send them to separate
processses in order to bypass the <a href="https://realpython.com/python-gil">GIL</a>.</p>
<h2 id="usage">Usage</h2>
<pre><code class="python">&gt;&gt;&gt; from concurrent.futures import ProcessPoolExecutor
</code></pre>
<pre><code class="python">&gt;&gt;&gt; def cpu_bound_task(id: str):
        print('doing:', id)
        for _ in range(10): 3**20000000
        print('returning:', id)
        return id
</code></pre>
<pre><code class="python">&gt;&gt;&gt; def main():
        input_data = range(5)
        with ProcessPoolExecutor(max_workers=4) as workers:
            for result in workers.map(cpu_bound_task, input_data):
                print('got result:', result)
</code></pre>
<pre><code class="python">&gt;&gt;&gt; main()
doing: 0
doing: 1
doing: 2
doing: 3
returning: 3
doing: 4
returning: 1
returning: 0
got result: 0
got result: 1
returning: 2
got result: 2
got result: 3
returning: 4
got result: 4
</code></pre>
<h3 id="solving-io-bound-tasks">Solving IO bound tasks</h3>
<p>The optimal way to perform IO bound tasks is to send them to separate threads.
Since there is a very low CPU usage, we don't care about the performance
bottleneck the <a href="https://realpython.com/python-gil">GIL</a> introduce because most
of the time every thread will be just waiting in idle state.</p>
<h2 id="usage_1">Usage</h2>
<pre><code class="python">&gt;&gt;&gt; from concurrent.futures import ThreadPoolExecutor
&gt;&gt;&gt; from time import sleep
</code></pre>
<pre><code class="python">&gt;&gt;&gt; def io_bound_task(id: str):
        print('doing:', id)
        sleep(1)
        print('returning:', id)
        return id
</code></pre>
<pre><code class="python">&gt;&gt;&gt; def main():
    input_data = range(5)
    with ThreadPoolExecutor(max_workers=1000) as workers:
        for result in workers.map(io_bound_task, input_data):
            print('got result:', result)
</code></pre>
<pre><code class="python">&gt;&gt;&gt; main()
doing: 0
doing: 1
doing: 2
doing: 3
doing: 4
returning: 2
returning: 4
returning: 1
returning: 0
returning: 3
got result: 0
got result: 1
got result: 2
got result: 3
got result: 4
</code></pre>
<h3 id="solving-it-with-asyncio">Solving it with asyncio</h3>
<p><a href="https://docs.python.org/3/library/asyncio.html">Asyncio</a> offers a different
approach:</p>
<h1 id="installing">Installing</h1>
<pre><code>$ pip install aioextensions
</code></pre>
<h1 id="using">Using</h1>
<pre><code>&gt;&gt;&gt; from aioextensions import *  # to import everything
&gt;&gt;&gt; from aioextensions import (  # recommended way
        unblock,
        unblock_cpu,
        resolve,
        schedule,
        # ...
    )
</code></pre>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/kamadorueda/aioextensions/blob/latest/src/aioextensions/__init__.py#L0-L547" class="git-link">Browse git</a>
</summary>
<pre><code class="python">&#34;&#34;&#34;High performance functions to work with the async IO.

[![Release](
https://img.shields.io/pypi/v/aioextensions?color=success&amp;label=Release&amp;style=flat-square)](
https://pypi.org/project/aioextensions)
[![Documentation](
https://img.shields.io/badge/Documentation-click_here!-success?style=flat-square)](
https://kamadorueda.github.io/aioextensions/)
[![Downloads](
https://img.shields.io/pypi/dm/aioextensions?label=Downloads&amp;style=flat-square)](
https://pypi.org/project/aioextensions)
[![Status](
https://img.shields.io/pypi/status/aioextensions?label=Status&amp;style=flat-square)](
https://pypi.org/project/aioextensions)
[![Coverage](
https://img.shields.io/badge/Coverage-100%25-success?style=flat-square)](
https://kamadorueda.github.io/aioextensions/)
[![License](
https://img.shields.io/pypi/l/aioextensions?color=success&amp;label=License&amp;style=flat-square)](
https://github.com/kamadorueda/aioextensions/blob/latest/LICENSE.md)

# Rationale

Modern services deal with a bunch of different tasks to perform:

![Latency comparison](
https://raw.githubusercontent.com/kamadorueda/aioextensions/latest/docs/static/latency.png)

The important thing to note is that tasks can be categorized in two groups:

## CPU bound tasks

Those that happen inside the CPU, with very low latency and exploit the full
potential of the hardware in the computer.

![Resources of an CPU bound task](
https://raw.githubusercontent.com/kamadorueda/aioextensions/latest/docs/static/resources_cpu_task.png)

Examples of these tasks include:

| Task                 | Latency in seconds |
|----------------------|-------------------:|
| CPU computation      |        0.000000001 |
| Memory access        |          0.0000001 |
| CPU Processing (1KB) |           0.000003 |
| Memory read (1MB)    |            0.00025 |

## IO bound tasks

Those that happen over a wire that transports data, with very high latencies
and do not exploit the full potential of the hardware because the only thing to
do is waiting until the data gets to the other end and comes back (round-trip)

![Resources of an IO bound task](
https://raw.githubusercontent.com/kamadorueda/aioextensions/latest/docs/static/resources_io_task.png)

Examples of these tasks include:

| Task                 | Latency in seconds |
|----------------------|-------------------:|
| Disk access          |            0.00015 |
| HTTP to localhost    |             0.0005 |
| Disk read (1MB)      |               0.02 |
| HTTP to internet     |               0.15 |

## Standard library

The Python&#39;s standard library offers the [concurrent.futures](
https://docs.python.org/3/library/concurrent.futures.html) module to work with
these problems.

You can use it to create a pool of Threads or Processes and send work to them:

-  Work done by a pool of Processes is executed in parallel: all CPU cores are
    being used.
-  Work done by a pool of Threads is done concurrently: tasks execution is
    overlapping, but not necessarily parallel: only 1 task can use the CPU
    while the remaining ones are waiting the
    [GIL](https://realpython.com/python-gil).

This is fine for most use cases, however, sometimes you need to solve
a mixture of tasks types in a hardware efficient way.

### Solving CPU bound tasks

The optimal way to perform CPU bound tasks is to send them to separate
processses in order to bypass the [GIL](https://realpython.com/python-gil).

Usage:

    &gt;&gt;&gt; from concurrent.futures import ProcessPoolExecutor

    &gt;&gt;&gt; def cpu_bound_task(id: str):
            print(&#39;doing:&#39;, id)
            for _ in range(10): 3**20000000
            print(&#39;returning:&#39;, id)
            return id

    &gt;&gt;&gt; def main():
            input_data = range(5)
            with ProcessPoolExecutor(max_workers=4) as workers:
                for result in workers.map(cpu_bound_task, input_data):
                    print(&#39;got result:&#39;, result)

    &gt;&gt;&gt; main()
    doing: 0
    doing: 1
    doing: 2
    doing: 3
    returning: 3
    doing: 4
    returning: 1
    returning: 0
    got result: 0
    got result: 1
    returning: 2
    got result: 2
    got result: 3
    returning: 4
    got result: 4

### Solving IO bound tasks

The optimal way to perform IO bound tasks is to send them to separate threads.
Since there is a very low CPU usage, we don&#39;t care about the performance
bottleneck the [GIL](https://realpython.com/python-gil) introduce because most
of the time every thread will be just waiting in idle state.

Usage:

    &gt;&gt;&gt; from concurrent.futures import ThreadPoolExecutor
    &gt;&gt;&gt; from time import sleep

    &gt;&gt;&gt; def io_bound_task(id: str):
            print(&#39;doing:&#39;, id)
            sleep(1)
            print(&#39;returning:&#39;, id)
            return id

    &gt;&gt;&gt; def main():
        input_data = range(5)
        with ThreadPoolExecutor(max_workers=1000) as workers:
            for result in workers.map(io_bound_task, input_data):
                print(&#39;got result:&#39;, result)

    &gt;&gt;&gt; main()
    doing: 0
    doing: 1
    doing: 2
    doing: 3
    doing: 4
    returning: 2
    returning: 4
    returning: 1
    returning: 0
    returning: 3
    got result: 0
    got result: 1
    got result: 2
    got result: 3
    got result: 4

### Solving it with asyncio

[Asyncio](https://docs.python.org/3/library/asyncio.html) offers a different
approach:



# Installing

    $ pip install aioextensions

# Using

    &gt;&gt;&gt; from aioextensions import *  # to import everything
    &gt;&gt;&gt; from aioextensions import (  # recommended way
            unblock,
            unblock_cpu,
            resolve,
            schedule,
            # ...
        )
&#34;&#34;&#34;

# Standard library
import asyncio
from concurrent.futures import (
    Executor,
    ProcessPoolExecutor,
    ThreadPoolExecutor,
)
from functools import (
    partial,
    wraps,
)
from itertools import (
    tee,
)
from os import (
    cpu_count,
)
from typing import (
    Any,
    Awaitable,
    Callable,
    cast,
    Dict,
    Iterable,
    Optional,
    Tuple,
    Type,
    TypeVar,
    Union,
)

# Third party libraries
import uvloop

# Constants
CPU_COUNT: int = cpu_count() or 1
_F = TypeVar(&#39;_F&#39;, bound=Callable[..., Any])
_T = TypeVar(&#39;_T&#39;)

# Linters
# pylint: disable=unsubscriptable-object


def block(
    function: Callable[..., Awaitable[_T]],
    *args: Any,
    **kwargs: Any,
) -&gt; _T:
    &#34;&#34;&#34;Execute an asynchronous function synchronously and return its result.

    Example:
        &gt;&gt;&gt; async def do(a, b=0):
                await something
                return a + b

        &gt;&gt;&gt; block(do, 1, b=2)

        &gt;&gt;&gt; 3

    This function acts as a drop-in replacement of asyncio.run and
    installs `uvloop` (the fastest event-loop implementation out there) first.

    .. tip::
        Use this as the entrypoint for your program.
    &#34;&#34;&#34;
    uvloop.install()
    return asyncio.run(function(*args, **kwargs))


def block_decorator(function: _F) -&gt; _F:
    &#34;&#34;&#34;Decorator to turn an asynchronous function into a synchronous one.

    Example:
        &gt;&gt;&gt; @block_decorator
            async def do(a, b=0):
                return a + b

        &gt;&gt;&gt; do(1, b=2) == 3

    This can be used as a bridge between synchronous and asynchronous code.
    &#34;&#34;&#34;

    @wraps(function)
    def wrapper(*args: Any, **kwargs: Any) -&gt; Any:
        return block(function, *args, **kwargs)

    return cast(_F, wrapper)


class ExecutorPool:

    def __init__(
        self,
        cls: Union[
            Type[ProcessPoolExecutor],
            Type[ThreadPoolExecutor],
        ],
    ) -&gt; None:
        self._cls = cls
        self._pool: Optional[Executor] = None

    def initialize(self, *, max_workers: Optional[int] = None) -&gt; None:
        if self._pool is not None:
            self._pool.shutdown(wait=False)

        self._pool = self._cls(max_workers=max_workers)

    def shutdown(self, *, wait: bool) -&gt; None:
        if self._pool is not None:
            self._pool.shutdown(wait=wait)
            self._pool = None

    @property
    def pool(self) -&gt; Executor:
        if self._pool is None:
            raise RuntimeError(&#39;Must call initialize first&#39;)

        return self._pool

    @property
    def initialized(self) -&gt; bool:
        return self._pool is not None


async def force_loop_cycle() -&gt; None:
    &#34;&#34;&#34;Force the event loop to perform one cycle.

    This can be used to suspend the execution of the current coroutine and
    yield control back to the event-loop.
    &#34;&#34;&#34;
    await asyncio.sleep(0)


def resolve(  # noqa: mccabe
    awaitables: Iterable[Awaitable[_T]],
    *,
    workers: int = 1024,
    worker_greediness: int = 0,
) -&gt; Iterable[Awaitable[_T]]:
    &#34;&#34;&#34;Resolve concurrently the input stream and yield back in the same order.

    The algorithm makes sure that at any point in time every worker is busy.
    Also, at any point in time there will be at most _number of `workers`_
    tasks being resolved concurrently.

    The `worker_greediness` parameter controlls how much each worker can
    process before waiting for you to retrieve results. This is important
    when the input stream is big as it allows you to control the memory usage.

    .. tip::
        This is similar to asyncio.as_completed. However it allows you
        to control how much resources are consumed throughout the execution,
        for instance:

        - How many open files will be opened at the same time
        - How many HTTP requests will be performed to a service (rate limit)
        - How many sockets will be opened concurrently
        - Etc

        This is useful for finite resources, for instance: the number
        of sockets provided by the operative system is limited; going beyond it
        would make the kernel to kill the program abruptly.

    Usage:
        &gt;&gt;&gt; async def do(n):
                print(&#39;running:&#39;, n)
                await asyncio.sleep(1)
                print(&#39;returning:&#39;, n)
                return n

        &gt;&gt;&gt; iterable = map(do, range(5))

        &gt;&gt;&gt; for next in resolve(iterable, workers=2):
                try:
                    print(&#39;got resolved result:&#39;, await next)
                except:
                    pass  # Handle possible exceptions

    Output:
        ```
        running: 0
        running: 1
        returning: 0
        returning: 1
        got resolved result: 0
        got resolved result: 1
        running: 2
        running: 3
        returning: 2
        returning: 3
        got resolved result: 2
        got resolved result: 3
        running: 4
        returning: 4
        got resolved result: 4
        ```

    Args:
        awaitables: An iterable (generator, list, tuple, set, etc) of
            awaitables (coroutine, asyncio.Task, or asyncio.Future).
        workers: The number of independent workers that will be processing
            the input stream.
        worker_greediness: How much tasks can a worker process before waiting
            for you to retrieve its results. 0 means unlimited.

    Yields:
        A future with the result of the next ready task. Futures are yielded in
        the same order of the input stream (opposite to asyncio.as_completed)

    .. tip::
        This approach may be many times faster than batching because
        workers are independent of each other and they are constantly fetching
        the next task as soon as they get free (as long as the greediness
        allows them).

    .. tip::
        If awaitables is an instance of Sized (has `__len__` prototype).
        This function will launch at most `len(awaitables)` workers.
    &#34;&#34;&#34;
    if workers &lt; 1:
        raise ValueError(&#39;workers must be &gt;= 1&#39;)
    if worker_greediness &lt; 0:
        raise ValueError(&#39;worker_greediness must be &gt;= 0&#39;)

    if hasattr(awaitables, &#39;__len__&#39;):
        workers = min(workers, len(awaitables))  # type: ignore

    loop = asyncio.get_event_loop()
    store: Dict[int, asyncio.Queue] = {}
    stream, stream_copy = tee(enumerate(awaitables))
    stream_finished = asyncio.Event()
    workers_up = asyncio.Event()
    workers_tasks: Dict[int, asyncio.Task] = {}

    async def worker() -&gt; None:
        done: asyncio.Queue = asyncio.Queue(worker_greediness)
        for index, awaitable in stream:
            store[index] = done
            future = loop.create_future()
            future.set_result(await schedule(awaitable, loop=loop))
            await done.put(future)
            workers_up.set()
        workers_up.set()
        stream_finished.set()

    async def start_workers() -&gt; None:
        for index in range(workers):
            if stream_finished.is_set():
                break
            workers_tasks[index] = asyncio.create_task(worker())
            await force_loop_cycle()
        await workers_up.wait()

    async def get_one(index: int) -&gt; Awaitable[_T]:
        if not workers_tasks:
            await start_workers()

        awaitable = await store.pop(index).get()
        result: Awaitable[_T] = (await awaitable).result()
        return result

    for index, _ in stream_copy:
        yield cast(Awaitable[_T], get_one(index))


async def collect(
    awaitables: Iterable[Awaitable[_T]],
    *,
    workers: int = 1024,
    worker_greediness: int = 0,
) -&gt; Tuple[_T, ...]:
    &#34;&#34;&#34;Resolve concurrently the input stream and return back in the same order.

    See `resolve` for more information on the algorithm used and parameters.

    Usage:
        &gt;&gt;&gt; async def do(n):
                print(&#39;running:&#39;, n)
                await asyncio.sleep(1)
                print(&#39;returning:&#39;, n)
                return n

        &gt;&gt;&gt; iterable = map(do, range(5))

        &gt;&gt;&gt; results = await collect(iterable, workers=2)

        &gt;&gt;&gt; print(results)

    Output:
        ```
        running: 0
        running: 1
        returning: 0
        returning: 1
        running: 2
        running: 3
        returning: 2
        returning: 3
        running: 4
        returning: 4
        (0, 1, 2, 3, 4)
        ```
    &#34;&#34;&#34;
    return tuple([
        await elem
        for elem in resolve(
            awaitables,
            workers=workers,
            worker_greediness=worker_greediness,
        )
    ])


def schedule(
    awaitable: Awaitable[_T],
    *,
    loop: Optional[asyncio.AbstractEventLoop] = None,
) -&gt; Awaitable[_T]:
    &#34;&#34;&#34;Schedule an awaitable in the event loop and return a wrapper for it.

    &#34;&#34;&#34;
    wrapper = (loop or asyncio.get_event_loop()).create_future()

    def _done_callback(future: asyncio.Future) -&gt; None:
        if not wrapper.done():
            wrapper.set_result(future)

    asyncio.create_task(awaitable).add_done_callback(_done_callback)

    return wrapper


async def unblock(
    function: Callable[..., _T],
    *args: Any,
    **kwargs: Any,
) -&gt; _T:
    &#34;&#34;&#34;Execute function(*args, **kwargs) in the specified thread executor.&#34;&#34;&#34;
    if not THREAD_POOL.initialized:
        THREAD_POOL.initialize(max_workers=10 * CPU_COUNT)

    return await asyncio.get_running_loop().run_in_executor(
        THREAD_POOL.pool, partial(function, *args, **kwargs),
    )


async def unblock_cpu(
    function: Callable[..., _T],
    *args: Any,
    **kwargs: Any,
) -&gt; _T:
    &#34;&#34;&#34;Execute function(*args, **kwargs) in the specified process executor.&#34;&#34;&#34;
    if not PROCESS_POOL.initialized:
        PROCESS_POOL.initialize(max_workers=CPU_COUNT)

    return await asyncio.get_running_loop().run_in_executor(
        PROCESS_POOL.pool, partial(function, *args, **kwargs),
    )


# Constants
PROCESS_POOL: ExecutorPool = ExecutorPool(ProcessPoolExecutor)
THREAD_POOL: ExecutorPool = ExecutorPool(ThreadPoolExecutor)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="aioextensions.block"><code class="name flex">
<span>def <span class="ident">block</span></span>(<span>function: Callable[..., Awaitable[~_T]], *args: Any, **kwargs: Any) ‑> ~_T</span>
</code></dt>
<dd>
<div class="desc"><p>Execute an asynchronous function synchronously and return its result.</p>
<h2 id="example">Example</h2>
<pre><code class="python">&gt;&gt;&gt; async def do(a, b=0):
        await something
        return a + b
</code></pre>
<pre><code class="python">&gt;&gt;&gt; block(do, 1, b=2)
</code></pre>
<pre><code class="python">&gt;&gt;&gt; 3
</code></pre>
<p>This function acts as a drop-in replacement of asyncio.run and
installs <code>uvloop</code> (the fastest event-loop implementation out there) first.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Use this as the entrypoint for your program.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/kamadorueda/aioextensions/blob/latest/src/aioextensions/__init__.py#L229-L252" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def block(
    function: Callable[..., Awaitable[_T]],
    *args: Any,
    **kwargs: Any,
) -&gt; _T:
    &#34;&#34;&#34;Execute an asynchronous function synchronously and return its result.

    Example:
        &gt;&gt;&gt; async def do(a, b=0):
                await something
                return a + b

        &gt;&gt;&gt; block(do, 1, b=2)

        &gt;&gt;&gt; 3

    This function acts as a drop-in replacement of asyncio.run and
    installs `uvloop` (the fastest event-loop implementation out there) first.

    .. tip::
        Use this as the entrypoint for your program.
    &#34;&#34;&#34;
    uvloop.install()
    return asyncio.run(function(*args, **kwargs))</code></pre>
</details>
</dd>
<dt id="aioextensions.block_decorator"><code class="name flex">
<span>def <span class="ident">block_decorator</span></span>(<span>function: ~_F) ‑> ~_F</span>
</code></dt>
<dd>
<div class="desc"><p>Decorator to turn an asynchronous function into a synchronous one.</p>
<h2 id="example">Example</h2>
<pre><code class="python">&gt;&gt;&gt; @block_decorator
    async def do(a, b=0):
        return a + b
</code></pre>
<pre><code class="python">&gt;&gt;&gt; do(1, b=2) == 3
</code></pre>
<p>This can be used as a bridge between synchronous and asynchronous code.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/kamadorueda/aioextensions/blob/latest/src/aioextensions/__init__.py#L255-L272" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def block_decorator(function: _F) -&gt; _F:
    &#34;&#34;&#34;Decorator to turn an asynchronous function into a synchronous one.

    Example:
        &gt;&gt;&gt; @block_decorator
            async def do(a, b=0):
                return a + b

        &gt;&gt;&gt; do(1, b=2) == 3

    This can be used as a bridge between synchronous and asynchronous code.
    &#34;&#34;&#34;

    @wraps(function)
    def wrapper(*args: Any, **kwargs: Any) -&gt; Any:
        return block(function, *args, **kwargs)

    return cast(_F, wrapper)</code></pre>
</details>
</dd>
<dt id="aioextensions.collect"><code class="name flex">
<span>async def <span class="ident">collect</span></span>(<span>awaitables: Iterable[Awaitable[~_T]], *, workers: int = 1024, worker_greediness: int = 0) ‑> Tuple[~_T, ...]</span>
</code></dt>
<dd>
<div class="desc"><p>Resolve concurrently the input stream and return back in the same order.</p>
<p>See <code><a title="aioextensions.resolve" href="#aioextensions.resolve">resolve()</a></code> for more information on the algorithm used and parameters.</p>
<h2 id="usage">Usage</h2>
<pre><code class="python">&gt;&gt;&gt; async def do(n):
        print('running:', n)
        await asyncio.sleep(1)
        print('returning:', n)
        return n
</code></pre>
<pre><code class="python">&gt;&gt;&gt; iterable = map(do, range(5))
</code></pre>
<pre><code class="python">&gt;&gt;&gt; results = await collect(iterable, workers=2)
</code></pre>
<pre><code class="python">&gt;&gt;&gt; print(results)
</code></pre>
<h2 id="output">Output</h2>
<pre><code>running: 0
running: 1
returning: 0
returning: 1
running: 2
running: 3
returning: 2
returning: 3
running: 4
returning: 4
(0, 1, 2, 3, 4)
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/kamadorueda/aioextensions/blob/latest/src/aioextensions/__init__.py#L451-L496" class="git-link">Browse git</a>
</summary>
<pre><code class="python">async def collect(
    awaitables: Iterable[Awaitable[_T]],
    *,
    workers: int = 1024,
    worker_greediness: int = 0,
) -&gt; Tuple[_T, ...]:
    &#34;&#34;&#34;Resolve concurrently the input stream and return back in the same order.

    See `resolve` for more information on the algorithm used and parameters.

    Usage:
        &gt;&gt;&gt; async def do(n):
                print(&#39;running:&#39;, n)
                await asyncio.sleep(1)
                print(&#39;returning:&#39;, n)
                return n

        &gt;&gt;&gt; iterable = map(do, range(5))

        &gt;&gt;&gt; results = await collect(iterable, workers=2)

        &gt;&gt;&gt; print(results)

    Output:
        ```
        running: 0
        running: 1
        returning: 0
        returning: 1
        running: 2
        running: 3
        returning: 2
        returning: 3
        running: 4
        returning: 4
        (0, 1, 2, 3, 4)
        ```
    &#34;&#34;&#34;
    return tuple([
        await elem
        for elem in resolve(
            awaitables,
            workers=workers,
            worker_greediness=worker_greediness,
        )
    ])</code></pre>
</details>
</dd>
<dt id="aioextensions.force_loop_cycle"><code class="name flex">
<span>async def <span class="ident">force_loop_cycle</span></span>(<span>) ‑> NoneType</span>
</code></dt>
<dd>
<div class="desc"><p>Force the event loop to perform one cycle.</p>
<p>This can be used to suspend the execution of the current coroutine and
yield control back to the event-loop.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/kamadorueda/aioextensions/blob/latest/src/aioextensions/__init__.py#L310-L316" class="git-link">Browse git</a>
</summary>
<pre><code class="python">async def force_loop_cycle() -&gt; None:
    &#34;&#34;&#34;Force the event loop to perform one cycle.

    This can be used to suspend the execution of the current coroutine and
    yield control back to the event-loop.
    &#34;&#34;&#34;
    await asyncio.sleep(0)</code></pre>
</details>
</dd>
<dt id="aioextensions.resolve"><code class="name flex">
<span>def <span class="ident">resolve</span></span>(<span>awaitables: Iterable[Awaitable[~_T]], *, workers: int = 1024, worker_greediness: int = 0) ‑> Iterable[Awaitable[~_T]]</span>
</code></dt>
<dd>
<div class="desc"><p>Resolve concurrently the input stream and yield back in the same order.</p>
<p>The algorithm makes sure that at any point in time every worker is busy.
Also, at any point in time there will be at most <em>number of <code>workers</code></em>
tasks being resolved concurrently.</p>
<p>The <code>worker_greediness</code> parameter controlls how much each worker can
process before waiting for you to retrieve results. This is important
when the input stream is big as it allows you to control the memory usage.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>This is similar to asyncio.as_completed. However it allows you
to control how much resources are consumed throughout the execution,
for instance:</p>
<ul>
<li>How many open files will be opened at the same time</li>
<li>How many HTTP requests will be performed to a service (rate limit)</li>
<li>How many sockets will be opened concurrently</li>
<li>Etc</li>
</ul>
<p>This is useful for finite resources, for instance: the number
of sockets provided by the operative system is limited; going beyond it
would make the kernel to kill the program abruptly.</p>
</div>
<h2 id="usage">Usage</h2>
<pre><code class="python">&gt;&gt;&gt; async def do(n):
        print('running:', n)
        await asyncio.sleep(1)
        print('returning:', n)
        return n
</code></pre>
<pre><code class="python">&gt;&gt;&gt; iterable = map(do, range(5))
</code></pre>
<pre><code class="python">&gt;&gt;&gt; for next in resolve(iterable, workers=2):
        try:
            print('got resolved result:', await next)
        except:
            pass  # Handle possible exceptions
</code></pre>
<h2 id="output">Output</h2>
<pre><code>running: 0
running: 1
returning: 0
returning: 1
got resolved result: 0
got resolved result: 1
running: 2
running: 3
returning: 2
returning: 3
got resolved result: 2
got resolved result: 3
running: 4
returning: 4
got resolved result: 4
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>awaitables</code></strong></dt>
<dd>An iterable (generator, list, tuple, set, etc) of
awaitables (coroutine, asyncio.Task, or asyncio.Future).</dd>
<dt><strong><code>workers</code></strong></dt>
<dd>The number of independent workers that will be processing
the input stream.</dd>
<dt><strong><code>worker_greediness</code></strong></dt>
<dd>How much tasks can a worker process before waiting
for you to retrieve its results. 0 means unlimited.</dd>
</dl>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>This approach may be many times faster than batching because
workers are independent of each other and they are constantly fetching
the next task as soon as they get free (as long as the greediness
allows them).</p>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>If awaitables is an instance of Sized (has <code>__len__</code> prototype).
This function will launch at most <code>len(awaitables)</code> workers.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/kamadorueda/aioextensions/blob/latest/src/aioextensions/__init__.py#L319-L448" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def resolve(  # noqa: mccabe
    awaitables: Iterable[Awaitable[_T]],
    *,
    workers: int = 1024,
    worker_greediness: int = 0,
) -&gt; Iterable[Awaitable[_T]]:
    &#34;&#34;&#34;Resolve concurrently the input stream and yield back in the same order.

    The algorithm makes sure that at any point in time every worker is busy.
    Also, at any point in time there will be at most _number of `workers`_
    tasks being resolved concurrently.

    The `worker_greediness` parameter controlls how much each worker can
    process before waiting for you to retrieve results. This is important
    when the input stream is big as it allows you to control the memory usage.

    .. tip::
        This is similar to asyncio.as_completed. However it allows you
        to control how much resources are consumed throughout the execution,
        for instance:

        - How many open files will be opened at the same time
        - How many HTTP requests will be performed to a service (rate limit)
        - How many sockets will be opened concurrently
        - Etc

        This is useful for finite resources, for instance: the number
        of sockets provided by the operative system is limited; going beyond it
        would make the kernel to kill the program abruptly.

    Usage:
        &gt;&gt;&gt; async def do(n):
                print(&#39;running:&#39;, n)
                await asyncio.sleep(1)
                print(&#39;returning:&#39;, n)
                return n

        &gt;&gt;&gt; iterable = map(do, range(5))

        &gt;&gt;&gt; for next in resolve(iterable, workers=2):
                try:
                    print(&#39;got resolved result:&#39;, await next)
                except:
                    pass  # Handle possible exceptions

    Output:
        ```
        running: 0
        running: 1
        returning: 0
        returning: 1
        got resolved result: 0
        got resolved result: 1
        running: 2
        running: 3
        returning: 2
        returning: 3
        got resolved result: 2
        got resolved result: 3
        running: 4
        returning: 4
        got resolved result: 4
        ```

    Args:
        awaitables: An iterable (generator, list, tuple, set, etc) of
            awaitables (coroutine, asyncio.Task, or asyncio.Future).
        workers: The number of independent workers that will be processing
            the input stream.
        worker_greediness: How much tasks can a worker process before waiting
            for you to retrieve its results. 0 means unlimited.

    Yields:
        A future with the result of the next ready task. Futures are yielded in
        the same order of the input stream (opposite to asyncio.as_completed)

    .. tip::
        This approach may be many times faster than batching because
        workers are independent of each other and they are constantly fetching
        the next task as soon as they get free (as long as the greediness
        allows them).

    .. tip::
        If awaitables is an instance of Sized (has `__len__` prototype).
        This function will launch at most `len(awaitables)` workers.
    &#34;&#34;&#34;
    if workers &lt; 1:
        raise ValueError(&#39;workers must be &gt;= 1&#39;)
    if worker_greediness &lt; 0:
        raise ValueError(&#39;worker_greediness must be &gt;= 0&#39;)

    if hasattr(awaitables, &#39;__len__&#39;):
        workers = min(workers, len(awaitables))  # type: ignore

    loop = asyncio.get_event_loop()
    store: Dict[int, asyncio.Queue] = {}
    stream, stream_copy = tee(enumerate(awaitables))
    stream_finished = asyncio.Event()
    workers_up = asyncio.Event()
    workers_tasks: Dict[int, asyncio.Task] = {}

    async def worker() -&gt; None:
        done: asyncio.Queue = asyncio.Queue(worker_greediness)
        for index, awaitable in stream:
            store[index] = done
            future = loop.create_future()
            future.set_result(await schedule(awaitable, loop=loop))
            await done.put(future)
            workers_up.set()
        workers_up.set()
        stream_finished.set()

    async def start_workers() -&gt; None:
        for index in range(workers):
            if stream_finished.is_set():
                break
            workers_tasks[index] = asyncio.create_task(worker())
            await force_loop_cycle()
        await workers_up.wait()

    async def get_one(index: int) -&gt; Awaitable[_T]:
        if not workers_tasks:
            await start_workers()

        awaitable = await store.pop(index).get()
        result: Awaitable[_T] = (await awaitable).result()
        return result

    for index, _ in stream_copy:
        yield cast(Awaitable[_T], get_one(index))</code></pre>
</details>
</dd>
<dt id="aioextensions.schedule"><code class="name flex">
<span>def <span class="ident">schedule</span></span>(<span>awaitable: Awaitable[~_T], *, loop: Union[asyncio.events.AbstractEventLoop, NoneType] = None) ‑> Awaitable[~_T]</span>
</code></dt>
<dd>
<div class="desc"><p>Schedule an awaitable in the event loop and return a wrapper for it.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/kamadorueda/aioextensions/blob/latest/src/aioextensions/__init__.py#L499-L515" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def schedule(
    awaitable: Awaitable[_T],
    *,
    loop: Optional[asyncio.AbstractEventLoop] = None,
) -&gt; Awaitable[_T]:
    &#34;&#34;&#34;Schedule an awaitable in the event loop and return a wrapper for it.

    &#34;&#34;&#34;
    wrapper = (loop or asyncio.get_event_loop()).create_future()

    def _done_callback(future: asyncio.Future) -&gt; None:
        if not wrapper.done():
            wrapper.set_result(future)

    asyncio.create_task(awaitable).add_done_callback(_done_callback)

    return wrapper</code></pre>
</details>
</dd>
<dt id="aioextensions.unblock"><code class="name flex">
<span>async def <span class="ident">unblock</span></span>(<span>function: Callable[..., ~_T], *args: Any, **kwargs: Any) ‑> ~_T</span>
</code></dt>
<dd>
<div class="desc"><p>Execute function(<em>args, </em>*kwargs) in the specified thread executor.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/kamadorueda/aioextensions/blob/latest/src/aioextensions/__init__.py#L518-L529" class="git-link">Browse git</a>
</summary>
<pre><code class="python">async def unblock(
    function: Callable[..., _T],
    *args: Any,
    **kwargs: Any,
) -&gt; _T:
    &#34;&#34;&#34;Execute function(*args, **kwargs) in the specified thread executor.&#34;&#34;&#34;
    if not THREAD_POOL.initialized:
        THREAD_POOL.initialize(max_workers=10 * CPU_COUNT)

    return await asyncio.get_running_loop().run_in_executor(
        THREAD_POOL.pool, partial(function, *args, **kwargs),
    )</code></pre>
</details>
</dd>
<dt id="aioextensions.unblock_cpu"><code class="name flex">
<span>async def <span class="ident">unblock_cpu</span></span>(<span>function: Callable[..., ~_T], *args: Any, **kwargs: Any) ‑> ~_T</span>
</code></dt>
<dd>
<div class="desc"><p>Execute function(<em>args, </em>*kwargs) in the specified process executor.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/kamadorueda/aioextensions/blob/latest/src/aioextensions/__init__.py#L532-L543" class="git-link">Browse git</a>
</summary>
<pre><code class="python">async def unblock_cpu(
    function: Callable[..., _T],
    *args: Any,
    **kwargs: Any,
) -&gt; _T:
    &#34;&#34;&#34;Execute function(*args, **kwargs) in the specified process executor.&#34;&#34;&#34;
    if not PROCESS_POOL.initialized:
        PROCESS_POOL.initialize(max_workers=CPU_COUNT)

    return await asyncio.get_running_loop().run_in_executor(
        PROCESS_POOL.pool, partial(function, *args, **kwargs),
    )</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="aioextensions.ExecutorPool"><code class="flex name class">
<span>class <span class="ident">ExecutorPool</span></span>
<span>(</span><span>cls: Union[Type[concurrent.futures.process.ProcessPoolExecutor], Type[concurrent.futures.thread.ThreadPoolExecutor]])</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/kamadorueda/aioextensions/blob/latest/src/aioextensions/__init__.py#L275-L307" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class ExecutorPool:

    def __init__(
        self,
        cls: Union[
            Type[ProcessPoolExecutor],
            Type[ThreadPoolExecutor],
        ],
    ) -&gt; None:
        self._cls = cls
        self._pool: Optional[Executor] = None

    def initialize(self, *, max_workers: Optional[int] = None) -&gt; None:
        if self._pool is not None:
            self._pool.shutdown(wait=False)

        self._pool = self._cls(max_workers=max_workers)

    def shutdown(self, *, wait: bool) -&gt; None:
        if self._pool is not None:
            self._pool.shutdown(wait=wait)
            self._pool = None

    @property
    def pool(self) -&gt; Executor:
        if self._pool is None:
            raise RuntimeError(&#39;Must call initialize first&#39;)

        return self._pool

    @property
    def initialized(self) -&gt; bool:
        return self._pool is not None</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="aioextensions.ExecutorPool.initialized"><code class="name">var <span class="ident">initialized</span> : bool</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/kamadorueda/aioextensions/blob/latest/src/aioextensions/__init__.py#L305-L307" class="git-link">Browse git</a>
</summary>
<pre><code class="python">@property
def initialized(self) -&gt; bool:
    return self._pool is not None</code></pre>
</details>
</dd>
<dt id="aioextensions.ExecutorPool.pool"><code class="name">var <span class="ident">pool</span> : concurrent.futures._base.Executor</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/kamadorueda/aioextensions/blob/latest/src/aioextensions/__init__.py#L298-L303" class="git-link">Browse git</a>
</summary>
<pre><code class="python">@property
def pool(self) -&gt; Executor:
    if self._pool is None:
        raise RuntimeError(&#39;Must call initialize first&#39;)

    return self._pool</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="aioextensions.ExecutorPool.initialize"><code class="name flex">
<span>def <span class="ident">initialize</span></span>(<span>self, *, max_workers: Union[int, NoneType] = None) ‑> NoneType</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/kamadorueda/aioextensions/blob/latest/src/aioextensions/__init__.py#L287-L291" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def initialize(self, *, max_workers: Optional[int] = None) -&gt; None:
    if self._pool is not None:
        self._pool.shutdown(wait=False)

    self._pool = self._cls(max_workers=max_workers)</code></pre>
</details>
</dd>
<dt id="aioextensions.ExecutorPool.shutdown"><code class="name flex">
<span>def <span class="ident">shutdown</span></span>(<span>self, *, wait: bool) ‑> NoneType</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/kamadorueda/aioextensions/blob/latest/src/aioextensions/__init__.py#L293-L296" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def shutdown(self, *, wait: bool) -&gt; None:
    if self._pool is not None:
        self._pool.shutdown(wait=wait)
        self._pool = None</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul>
<li><a href="#rationale">Rationale</a><ul>
<li><a href="#cpu-bound-tasks">CPU bound tasks</a></li>
<li><a href="#io-bound-tasks">IO bound tasks</a></li>
<li><a href="#standard-library">Standard library</a><ul>
<li><a href="#solving-cpu-bound-tasks">Solving CPU bound tasks</a></li>
<li><a href="#solving-io-bound-tasks">Solving IO bound tasks</a></li>
<li><a href="#solving-it-with-asyncio">Solving it with asyncio</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#installing">Installing</a></li>
<li><a href="#using">Using</a></li>
</ul>
</div>
<ul id="index">
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="two-column">
<li><code><a title="aioextensions.block" href="#aioextensions.block">block</a></code></li>
<li><code><a title="aioextensions.block_decorator" href="#aioextensions.block_decorator">block_decorator</a></code></li>
<li><code><a title="aioextensions.collect" href="#aioextensions.collect">collect</a></code></li>
<li><code><a title="aioextensions.force_loop_cycle" href="#aioextensions.force_loop_cycle">force_loop_cycle</a></code></li>
<li><code><a title="aioextensions.resolve" href="#aioextensions.resolve">resolve</a></code></li>
<li><code><a title="aioextensions.schedule" href="#aioextensions.schedule">schedule</a></code></li>
<li><code><a title="aioextensions.unblock" href="#aioextensions.unblock">unblock</a></code></li>
<li><code><a title="aioextensions.unblock_cpu" href="#aioextensions.unblock_cpu">unblock_cpu</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="aioextensions.ExecutorPool" href="#aioextensions.ExecutorPool">ExecutorPool</a></code></h4>
<ul class="">
<li><code><a title="aioextensions.ExecutorPool.initialize" href="#aioextensions.ExecutorPool.initialize">initialize</a></code></li>
<li><code><a title="aioextensions.ExecutorPool.initialized" href="#aioextensions.ExecutorPool.initialized">initialized</a></code></li>
<li><code><a title="aioextensions.ExecutorPool.pool" href="#aioextensions.ExecutorPool.pool">pool</a></code></li>
<li><code><a title="aioextensions.ExecutorPool.shutdown" href="#aioextensions.ExecutorPool.shutdown">shutdown</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.8.4</a>.</p>
</footer>
</body>
</html>